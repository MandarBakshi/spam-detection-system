{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9aed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c9c09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MandarPC:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SpamDetectionSession</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1d4b0b28940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkSession = SparkSession.builder.appName('SpamDetectionSession').getOrCreate()\n",
    "sparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcac3bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|Category|             Message|\n",
      "+--------+--------------------+\n",
      "|     ham|Go until jurong p...|\n",
      "|     ham|Ok lar... Joking ...|\n",
      "|    spam|Free entry in 2 a...|\n",
      "|     ham|U dun say so earl...|\n",
      "|     ham|Nah I don't think...|\n",
      "|    spam|FreeMsg Hey there...|\n",
      "|     ham|Even my brother i...|\n",
      "|     ham|As per your reque...|\n",
      "|    spam|WINNER!! As a val...|\n",
      "|    spam|Had your mobile 1...|\n",
      "|     ham|I'm gonna be home...|\n",
      "|    spam|SIX chances to wi...|\n",
      "|    spam|URGENT! You have ...|\n",
      "|     ham|I've been searchi...|\n",
      "|     ham|I HAVE A DATE ON ...|\n",
      "|    spam|XXXMobileMovieClu...|\n",
      "|     ham|Oh k...i'm watchi...|\n",
      "|     ham|Eh u remember how...|\n",
      "|     ham|Fine if thats th...|\n",
      "|    spam|England v Macedon...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = sparkSession.read.csv('../resources/datasets/spam_dataset.csv', header=True)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e401af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------+\n",
      "|Category|             Message|length|\n",
      "+--------+--------------------+------+\n",
      "|     ham|Go until jurong p...|   111|\n",
      "|     ham|Ok lar... Joking ...|    29|\n",
      "|    spam|Free entry in 2 a...|   155|\n",
      "|     ham|U dun say so earl...|    49|\n",
      "|     ham|Nah I don't think...|    61|\n",
      "|    spam|FreeMsg Hey there...|   147|\n",
      "|     ham|Even my brother i...|    77|\n",
      "|     ham|As per your reque...|   160|\n",
      "|    spam|WINNER!! As a val...|   157|\n",
      "|    spam|Had your mobile 1...|   154|\n",
      "|     ham|I'm gonna be home...|   109|\n",
      "|    spam|SIX chances to wi...|   136|\n",
      "|    spam|URGENT! You have ...|   155|\n",
      "|     ham|I've been searchi...|   196|\n",
      "|     ham|I HAVE A DATE ON ...|    35|\n",
      "|    spam|XXXMobileMovieClu...|   149|\n",
      "|     ham|Oh k...i'm watchi...|    26|\n",
      "|     ham|Eh u remember how...|    81|\n",
      "|     ham|Fine if thats th...|    56|\n",
      "|    spam|England v Macedon...|   155|\n",
      "+--------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "\n",
    "df1 = df1.withColumn('length', length(df1['Message']))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e18cf",
   "metadata": {},
   "source": [
    "# Pre-processing phase\n",
    "- Involves cleaning the data\n",
    "- Generating the columns required for training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc6d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='Message', outputCol='tokens')\n",
    "removedStopWords = StopWordsRemover(inputCol='tokens', outputCol='removed_stop_words')\n",
    "countVectorizer = CountVectorizer(inputCol='removed_stop_words', outputCol='vectorized')\n",
    "idf = IDF(inputCol='vectorized', outputCol='idf')\n",
    "labels = StringIndexer(inputCol='Category', outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b7d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "vAssembler = VectorAssembler(inputCols=['idf', 'length'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d67471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|Category|             Message|length|              tokens|  removed_stop_words|          vectorized|                 idf|            features|label|\n",
      "+--------+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|     ham|Go until jurong p...|   111|[go, until, juron...|[go, jurong, poin...|(13421,[7,10,32,6...|(13421,[7,10,32,6...|(13422,[7,10,32,6...|  0.0|\n",
      "|     ham|Ok lar... Joking ...|    29|[ok, lar..., joki...|[ok, lar..., joki...|(13421,[0,24,296,...|(13421,[0,24,296,...|(13422,[0,24,296,...|  0.0|\n",
      "|    spam|Free entry in 2 a...|   155|[free, entry, in,...|[free, entry, 2, ...|(13421,[2,13,19,2...|(13421,[2,13,19,2...|(13422,[2,13,19,2...|  1.0|\n",
      "|     ham|U dun say so earl...|    49|[u, dun, say, so,...|[u, dun, say, ear...|(13421,[0,72,78,1...|(13421,[0,72,78,1...|(13422,[0,72,78,1...|  0.0|\n",
      "|     ham|Nah I don't think...|    61|[nah, i, don't, t...|[nah, think, goes...|(13421,[36,131,31...|(13421,[36,131,31...|(13422,[36,131,31...|  0.0|\n",
      "|    spam|FreeMsg Hey there...|   147|[freemsg, hey, th...|[freemsg, hey, da...|(13421,[11,59,139...|(13421,[11,59,139...|(13422,[11,59,139...|  1.0|\n",
      "|     ham|Even my brother i...|    77|[even, my, brothe...|[even, brother, l...|(13421,[11,52,108...|(13421,[11,52,108...|(13422,[11,52,108...|  0.0|\n",
      "|     ham|As per your reque...|   160|[as, per, your, r...|[per, request, 'm...|(13421,[124,185,4...|(13421,[124,185,4...|(13422,[124,185,4...|  0.0|\n",
      "|    spam|WINNER!! As a val...|   157|[winner!!, as, a,...|[winner!!, valued...|(13421,[1,47,123,...|(13421,[1,47,123,...|(13422,[1,47,123,...|  1.0|\n",
      "|    spam|Had your mobile 1...|   154|[had, your, mobil...|[mobile, 11, mont...|(13421,[0,1,13,27...|(13421,[0,1,13,27...|(13422,[0,1,13,27...|  1.0|\n",
      "|     ham|I'm gonna be home...|   109|[i'm, gonna, be, ...|[gonna, home, soo...|(13421,[18,43,116...|(13421,[18,43,116...|(13422,[18,43,116...|  0.0|\n",
      "|    spam|SIX chances to wi...|   136|[six, chances, to...|[six, chances, wi...|(13421,[8,17,37,8...|(13421,[8,17,37,8...|(13422,[8,17,37,8...|  1.0|\n",
      "|    spam|URGENT! You have ...|   155|[urgent!, you, ha...|[urgent!, won, 1,...|(13421,[13,29,47,...|(13421,[13,29,47,...|(13422,[13,29,47,...|  1.0|\n",
      "|     ham|I've been searchi...|   196|[i've, been, sear...|[searching, right...|(13421,[39,96,223...|(13421,[39,96,223...|(13422,[39,96,223...|  0.0|\n",
      "|     ham|I HAVE A DATE ON ...|    35|[i, have, a, date...|[date, sunday, wi...|(13421,[544,1680,...|(13421,[544,1680,...|(13422,[544,1680,...|  0.0|\n",
      "|    spam|XXXMobileMovieClu...|   149|[xxxmobilemoviecl...|[xxxmobilemoviecl...|(13421,[29,107,11...|(13421,[29,107,11...|(13422,[29,107,11...|  1.0|\n",
      "|     ham|Oh k...i'm watchi...|    26|[oh, k...i'm, wat...|[oh, k...i'm, wat...|(13421,[80,211,47...|(13421,[80,211,47...|(13422,[80,211,47...|  0.0|\n",
      "|     ham|Eh u remember how...|    81|[eh, u, remember,...|[eh, u, remember,...|(13421,[0,2,49,13...|(13421,[0,2,49,13...|(13422,[0,2,49,13...|  0.0|\n",
      "|     ham|Fine if thats th...|    56|[fine, if, thats...|[fine, thats, wa...|(13421,[0,74,101,...|(13421,[0,74,101,...|(13422,[0,74,101,...|  0.0|\n",
      "|    spam|England v Macedon...|   155|[england, v, mace...|[england, v, mace...|(13421,[4,29,34,6...|(13421,[4,29,34,6...|(13422,[4,29,34,6...|  1.0|\n",
      "+--------+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "inputFeatures = [tokenizer, removedStopWords, countVectorizer, idf, vAssembler, labels]\n",
    "\n",
    "pipeline = Pipeline(stages = inputFeatures)\n",
    "cleaner = pipeline.fit(df1)\n",
    "\n",
    "cleaned_df = cleaner.transform(df1)\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3747e3",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a890f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "df2 = cleaned_df.select(['label', 'features'])\n",
    "(train, test) = df2.randomSplit([0.7, 0.3], seed=11)\n",
    "\n",
    "nb = NaiveBayes()\n",
    "model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00aace7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(13422,[0,1,5,15,...|[-1009.8904044217...|[1.0,6.5521301247...|       0.0|\n",
      "|  0.0|(13422,[0,1,5,20,...|[-815.91608031702...|[1.0,3.4125044327...|       0.0|\n",
      "|  0.0|(13422,[0,1,9,14,...|[-549.95711003174...|[1.0,1.0865324357...|       0.0|\n",
      "|  0.0|(13422,[0,1,10,31...|[-875.28473229510...|[1.0,5.2375721078...|       0.0|\n",
      "|  0.0|(13422,[0,1,12,34...|[-445.55485354728...|[1.0,2.0561759442...|       0.0|\n",
      "|  0.0|(13422,[0,1,14,18...|[-1366.4093537066...|[1.0,8.4369525190...|       0.0|\n",
      "|  0.0|(13422,[0,1,14,81...|[-690.13920610716...|[1.0,4.0505834473...|       0.0|\n",
      "|  0.0|(13422,[0,1,15,20...|[-696.31193947636...|[1.0,3.7102911639...|       0.0|\n",
      "|  0.0|(13422,[0,1,21,27...|[-769.42623970917...|[1.0,1.8812512980...|       0.0|\n",
      "|  0.0|(13422,[0,1,29,11...|[-592.44192451270...|[1.0,7.3523435958...|       0.0|\n",
      "|  0.0|(13422,[0,1,43,68...|[-614.54835003678...|[0.99971397695664...|       0.0|\n",
      "|  0.0|(13422,[0,1,413,6...|[-317.0661753646,...|[0.99999999810171...|       0.0|\n",
      "|  0.0|(13422,[0,1,873,1...|[-94.552209392533...|[0.99999999445917...|       0.0|\n",
      "|  0.0|(13422,[0,2,3,4,6...|[-1282.7343212019...|[1.0,2.6768449248...|       0.0|\n",
      "|  0.0|(13422,[0,2,3,5,6...|[-2580.2603432812...|[1.0,3.9633377693...|       0.0|\n",
      "|  0.0|(13422,[0,2,3,5,2...|[-495.57270619220...|[1.0,4.7371833122...|       0.0|\n",
      "|  0.0|(13422,[0,2,4,5,1...|[-1630.0715087822...|[1.0,3.7206756900...|       0.0|\n",
      "|  0.0|(13422,[0,2,4,8,2...|[-550.94040403766...|[1.0,3.7323025054...|       0.0|\n",
      "|  0.0|(13422,[0,2,4,11,...|[-1230.9136952747...|[1.0,2.9991435655...|       0.0|\n",
      "|  0.0|(13422,[0,2,7,8,1...|[-704.81356368697...|[1.0,3.2259705833...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = model.transform(test)\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c630f",
   "metadata": {},
   "source": [
    "# Calculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f812eeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  91.69316582517087\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "accuracy = evaluator.evaluate(res)\n",
    "\n",
    "print(\"Accuracy = \", accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cea939cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the spark session\n",
    "sparkSession.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf45894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
